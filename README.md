# ü™ô Metal Price ETL Pipeline (Gold & Silver) ‚Äî Airflow + PostgreSQL

This project automatically collects live gold/silver prices, validates the data, and stores it into PostgreSQL every **6 hours** using Apache Airflow. It is built as a clean, modular ETL pipeline: **Extract ‚Üí Transform ‚Üí Validate ‚Üí Load**.

The goal: maintain a reliable metal-price dataset for analysis, dashboards, and trading insights.

## üöÄ What This Pipeline Does
| Step      | Action                                                                             |
| --------- | ---------------------------------------------------------------------------------- |
| Extract   | Fetch gold/silver prices from **GoldAPI** + USD‚ÜíIDR rate from **ExchangeRate API** |
| Transform | Convert timestamp, compute IDR price, clean & shape record                         |
| Validate  | Check required fields + logical data sanity                                        |
| Load      | Insert clean record into PostgreSQL table `metal_prices`                           |

Runs automatically every **6 hours**.

## üìÇ Project Structure

```
dags/
 ‚îî‚îÄ metal_price_dags.py      # Airflow DAG
src/
 ‚îú‚îÄ extract.py               # API calls
 ‚îú‚îÄ transform.py             # Data mapping + price conversion
 ‚îú‚îÄ validate.py              # Data QC rules
 ‚îî‚îÄ load.py                  # DB insert logic
table_schema.sql             # Database table schema
docker-compose.yml           # Airflow + Postgres services
```


## ‚è± Schedule

```python
schedule_interval="0 */6 * * *"
```

Pipeline runs daily at: **00:00, 06:00, 12:00, 18:00 UTC**


## ‚öôÔ∏è Setup

### 1Ô∏è‚É£ Start Airflow + PostgreSQL

```bash
docker compose up -d
```

### 2Ô∏è‚É£ Open Airflow UI

üìç [http://localhost:8080](http://localhost:8080)

User: `airflow`
Pass: `airflow`

### 3Ô∏è‚É£ Configure Connections in Airflow

| ID                  | Purpose                                       |
| ------------------- | --------------------------------------------- |
| `metal_api`         | GoldAPI (HTTP; API key stored in Extras JSON) |
| `exchange_rate_api` | ExchangeRate API (HTTP; API key in Extras)    |
| `my_postgres`       | Postgres database connection                  |


## üíæ Database Table

```sql
CREATE TABLE metal_prices (
  id SERIAL PRIMARY KEY,
  timestamp TIMESTAMP NOT NULL,
  metal TEXT,
  currency TEXT,
  exchange TEXT,
  symbol TEXT,
  price_usd NUMERIC,
  price_idr NUMERIC,
  prev_close_price NUMERIC,
  open_price NUMERIC,
  high_price NUMERIC,
  low_price NUMERIC,
  ch NUMERIC,
  chp NUMERIC,
  ingestion_times TIMESTAMP NOT NULL
);
```


## üéØ Why This Pipeline Exists

* Demonstrates real-world Data Engineering skills
* Shows Airflow DAG design & modular ETL code
* Captures market data reliably over time
* Great foundation for dashboards & trading models

This can easily extend to other assets: crypto, forex, commodities, indices, etc.

## üì∏ Screenshot placeholders

| Purpose         | File                      |
| --------------- | ------------------------- |
| DAG Graph       | `docs/img/dag_graph.png`  |
| Task Grid       | `docs/img/task_grid.png`  |
| Log Sample      | `docs/img/log_sample.png` |
| DB Data Preview | `docs/img/db_records.png` |

## üöß Future Upgrades

* Slack/telegram alerts for failures
* Backfill historical price data
* Grafana dashboard

## ‚úÖ Summary

This project shows:

* Automated data ingestion pipeline
* Airflow orchestration & XCom usage
* API integration & error handling
* ETL separation with validation layer
* Persistent storage in PostgreSQL

## üë®‚Äçüíª Author

Data Engineering Portfolio Project
Built with ‚ù§Ô∏è using Python, Airflow, Docker, and PostgreSQL